{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b1bc3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#For Preprocessing\n",
    "import re   \n",
    "import nltk \n",
    "# nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec253e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset into df folder\n",
    "df = pd.read_csv(\"emotion_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83458f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d818ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21459 entries, 0 to 21458\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Text     21459 non-null  object\n",
      " 1   Emotion  21459 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 335.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67da410c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21459, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c40fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the tweets\n",
    "# clearning the text\n",
    "def clean_and_process(text):\n",
    "    \"\"\"\n",
    "    This function removes any stopwords in the text\n",
    "    It also removes punctuations\n",
    "    and lastly it lemmatixe the word into its root form\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # remove non letters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # tokenize the text into words\n",
    "    words = text.split()\n",
    "    # remove stopwords\n",
    "    words = [w for w in words if w not in stopwords]\n",
    "    # apply stemming\n",
    "    #words = [PorterStemmer().stem(w) for w in words]\n",
    "    words = [wordnet_lemmatizer.lemmatize(w) for w in words]\n",
    "    # return a new sentense with the applied functions\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7d4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global vars\n",
    "# lematizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# remove stopwords from the text column\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b143c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text -->   i started feeling sentimental about dolls i had as a child and so began a collection of vintage barbie dolls from the sixties\n",
      "\n",
      "Processed text -->   started feeling sentimental doll child began collection vintage barbie doll sixty\n"
     ]
    }
   ],
   "source": [
    "# check sample\n",
    "print(\"Original text -->  \", df['Text'][18])\n",
    "print(\"\\nProcessed text -->  \", clean_and_process(df['Text'][18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e5a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the create a new cleaned column\n",
    "df['cleaned'] = df['Text'].apply(clean_and_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ca72f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>didnt feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>feeling grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion  \\\n",
       "0                            i didnt feel humiliated  sadness   \n",
       "1  i can go from feeling so hopeless to so damned...  sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong    anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...     love   \n",
       "4                               i am feeling grouchy    anger   \n",
       "\n",
       "                                             cleaned  \n",
       "0                              didnt feel humiliated  \n",
       "1  go feeling hopeless damned hopeful around some...  \n",
       "2          im grabbing minute post feel greedy wrong  \n",
       "3  ever feeling nostalgic fireplace know still pr...  \n",
       "4                                    feeling grouchy  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4bf66",
   "metadata": {},
   "source": [
    "## Preparation for Model Training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ca9cc",
   "metadata": {},
   "source": [
    "- We need to create a text vectorizer.\n",
    "- We must use the whole dataset to create the vectorizer for similarity purpose.\n",
    "- After fitting the vectorizer , transfroming will be done as per datase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c269c9",
   "metadata": {},
   "source": [
    "## We will use both TFIDF and COUNTVECTORIZER for vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f108b731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# define vectorizers\n",
    "# count vectorizer\n",
    "countVect = CountVectorizer() \n",
    "# frequency vectorizer.\n",
    "tfidfVect = TfidfVectorizer()\n",
    "\n",
    "# fit count vectorizer\n",
    "countVect.fit(df['cleaned'])\n",
    "# fit tdifvector\n",
    "tfidfVect.fit(df['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ccc94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21459, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01fb6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "622e2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the y/label/outcome column\n",
    "\n",
    "y = df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8babe52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned'], y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c4128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19313,), (19313,), (2146,), (2146,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape , X_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d53614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are using the object for countvectorizer and tdfif vectorizers fitted above to transform the text to vectors\n",
    "# transform the training to vects\n",
    "X_train_count = countVect.transform(X_train)\n",
    "X_train_tdfif = tfidfVect.transform(X_train)\n",
    "\n",
    "\n",
    "# transform the testing data\n",
    "X_test_tdfif = tfidfVect.transform(X_test)\n",
    "X_test_count = countVect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f32e90",
   "metadata": {},
   "source": [
    "## OUR Sentiments are in textual/categorical form\n",
    "- We need to turn them into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea804ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e40613",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_object = LabelEncoder()\n",
    "\n",
    "# encode for only validation and train datasets\n",
    "lbl_object.fit(y)\n",
    "\n",
    "# encode the labels\n",
    "Ytrain = lbl_object.transform(y_train)\n",
    "Ytest = lbl_object.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ba7d9",
   "metadata": {},
   "source": [
    "## Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26c08c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score , accuracy_score , precision_score , recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88531605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_scores(Ytrue , Ypred):\n",
    "    print(\"Accuracy Score {:.4f}\".format(accuracy_score(Ytrue , Ypred)))\n",
    "    print(\"F1 Score {:.4f}\".format(f1_score(Ytrue , Ypred , average='weighted')))\n",
    "    print(\"Precision Score {:.4f}\".format(precision_score(Ytrue , Ypred , average='weighted')))\n",
    "    print(\"Recall Score {:.4f}\".format(recall_score(Ytrue , Ypred , average='weighted')))\n",
    "\n",
    "    \n",
    "    # create a function to draw confusion matrix and showing the model statistics\n",
    "    # confussion matrix plot\n",
    "def show_model_stats(model_name , Model , x_test , y_test):\n",
    "    # get prdictions\n",
    "    print(f\"\\t\\t********** {Model}  Evaluation **********\\n\")\n",
    "    from sklearn.metrics import accuracy_score , confusion_matrix , classification_report , f1_score\n",
    "    prediction = model_name.predict(x_test)\n",
    "    print(f\"Accuracy is   {accuracy_score(y_test , prediction)*100}%\")\n",
    "    print(f\"F1 Score is   {f1_score(y_test , prediction , average='weighted')*100}%\\n\")\n",
    "    # classifciation reports\n",
    "    print(classification_report(y_test, prediction))\n",
    "    print(\"\\n\")\n",
    "    c_matrix = confusion_matrix(y_test, prediction)\n",
    "     # plot confusion matrix for better view\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(c_matrix , annot= True ,fmt=\"\" ,  annot_kws={\"size\": 10})\n",
    "    plt.xlabel(\"Actual Label\")\n",
    "    plt.ylabel(\"Predicted Label\")\n",
    "    plt.title(f\"Confusion Matrix Plot for {Model} classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7cd3a",
   "metadata": {},
   "source": [
    "## 1. BaseLine Model Logisticregression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6661f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******COUNT Vectorizer on Logistic regression Statistics*********\n",
      "Accuracy Score 0.8826\n",
      "F1 Score 0.8833\n",
      "Precision Score 0.8852\n",
      "Recall Score 0.8826\n",
      "\n",
      "\n",
      "******TFIDF Vectorizer on Logistic regression Statistics*********\n",
      "Accuracy Score 0.8611\n",
      "F1 Score 0.8659\n",
      "Precision Score 0.8789\n",
      "Recall Score 0.8611\n"
     ]
    }
   ],
   "source": [
    "# define logisticregression models for both tdfif and count vectorizers\n",
    "logit_tdif = LogisticRegression(n_jobs =-1)\n",
    "logit_count = LogisticRegression(n_jobs =-1)\n",
    "\n",
    "\n",
    "# train the models\n",
    "# train and get score for each.\n",
    "logit_count.fit(X_train_count , Ytrain)\n",
    "logic_pred1 = logit_count.predict(X_test_count)\n",
    "print(\"******COUNT Vectorizer on Logistic regression Statistics*********\")\n",
    "get_basic_scores(logic_pred1 , Ytest)\n",
    "\n",
    "print(\"\\n\\n******TFIDF Vectorizer on Logistic regression Statistics*********\")\n",
    "logit_tdif.fit(X_train_tdfif , Ytrain)\n",
    "logic_pred2 = logit_tdif.predict(X_test_tdfif)\n",
    "get_basic_scores(logic_pred2 , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ada411",
   "metadata": {},
   "source": [
    "## 2. MultinomialNB (a naive bayes model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c26eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******COUNT Vectorizer on MultinomialNB Statistics*********\n",
      "Accuracy Score 0.7856\n",
      "F1 Score 0.8038\n",
      "Precision Score 0.8448\n",
      "Recall Score 0.7856\n",
      "\n",
      "\n",
      "******TFIDF Vectorizer on MultinomialNB Statistics*********\n",
      "Accuracy Score 0.6789\n",
      "F1 Score 0.7499\n",
      "Precision Score 0.9030\n",
      "Recall Score 0.6789\n"
     ]
    }
   ],
   "source": [
    "# try out multinomial model\n",
    "nb_count = MultinomialNB()\n",
    "nb_tdif = MultinomialNB()\n",
    "nb_count.fit(X_train_count , Ytrain)\n",
    "\n",
    "nbpred1 = nb_count.predict(X_test_count)\n",
    "print(\"******COUNT Vectorizer on MultinomialNB Statistics*********\")\n",
    "get_basic_scores(nbpred1 , Ytest)\n",
    "print(\"\\n\\n******TFIDF Vectorizer on MultinomialNB Statistics*********\")\n",
    "nb_tdif.fit(X_train_tdfif , Ytrain)\n",
    "nbpred2 = nb_tdif.predict(X_test_tdfif)\n",
    "get_basic_scores(nbpred2 , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fce17c",
   "metadata": {},
   "source": [
    "## 3.Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db5d5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******COUNT Vectorizer on Decision tree Classier Statistics*********\n",
      "Accuracy Score 0.8709\n",
      "F1 Score 0.8704\n",
      "Precision Score 0.8713\n",
      "Recall Score 0.8709\n",
      "\n",
      "\n",
      "******TFIDF Vectorizer on Decision tree Classifier Statistics*********\n",
      "Accuracy Score 0.8630\n",
      "F1 Score 0.8624\n",
      "Precision Score 0.8633\n",
      "Recall Score 0.8630\n"
     ]
    }
   ],
   "source": [
    "dec_count = DecisionTreeClassifier()\n",
    "dec_tdif = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "dec_count.fit(X_train_count , Ytrain)\n",
    "dec_pred1 = dec_count.predict(X_test_count)\n",
    "print(\"******COUNT Vectorizer on Decision tree Classier Statistics*********\")\n",
    "get_basic_scores(dec_pred1 , Ytest)\n",
    "\n",
    "print(\"\\n\\n******TFIDF Vectorizer on Decision tree Classifier Statistics*********\")\n",
    "dec_tdif.fit(X_train_tdfif , Ytrain)\n",
    "dec_pred2 = dec_tdif.predict(X_test_tdfif)\n",
    "get_basic_scores(dec_pred2 , Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bcd6da",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1cc94d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******COUNT Vectorizer on Random forest Classier Statistics*********\n",
      "Accuracy Score 0.8621\n",
      "F1 Score 0.8620\n",
      "Precision Score 0.8641\n",
      "Recall Score 0.8621\n",
      "\n",
      "\n",
      "******TFIDF Vectorizer on Random forest Statistics*********\n",
      "Accuracy Score 0.8565\n",
      "F1 Score 0.8571\n",
      "Precision Score 0.8598\n",
      "Recall Score 0.8565\n"
     ]
    }
   ],
   "source": [
    "random_tfidf = RandomForestClassifier(n_estimators=10)\n",
    "random_count = RandomForestClassifier(n_estimators =10)\n",
    "\n",
    "random_count.fit(X_train_count , Ytrain)\n",
    "random_pred1 = random_count.predict(X_test_count)\n",
    "print(\"******COUNT Vectorizer on Random forest Classier Statistics*********\")\n",
    "get_basic_scores(random_pred1 , Ytest)\n",
    "\n",
    "print(\"\\n\\n******TFIDF Vectorizer on Random forest Statistics*********\")\n",
    "random_tfidf.fit(X_train_tdfif , Ytrain)\n",
    "random_pred2 = random_tfidf.predict(X_test_tdfif)\n",
    "get_basic_scores(random_pred2 , Ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610abd27",
   "metadata": {},
   "source": [
    "## 5. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8560585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Count Vectorizer on SVM***********\n",
      "Accuracy Score 0.8276\n",
      "F1 Score 0.8339\n",
      "Precision Score 0.8545\n",
      "Recall Score 0.8276\n",
      "******** TFIDF Vectorizer on SVM***********\n",
      "Accuracy Score 0.8518\n",
      "F1 Score 0.8564\n",
      "Precision Score 0.8700\n",
      "Recall Score 0.8518\n"
     ]
    }
   ],
   "source": [
    "svm_tdif = SVC()\n",
    "svm_count = SVC()\n",
    "\n",
    "svm_count.fit(X_train_count , Ytrain)\n",
    "svm_pred1 = svm_count.predict(X_test_count)\n",
    "print(\"******** Count Vectorizer on SVM***********\")\n",
    "get_basic_scores(svm_pred1 , Ytest)\n",
    "\n",
    "svm_tdif.fit(X_train_tdfif , Ytrain)\n",
    "svm_pred2 = svm_tdif.predict(X_test_tdfif)\n",
    "\n",
    "print(\"******** TFIDF Vectorizer on SVM***********\")\n",
    "get_basic_scores(svm_pred2 , Ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00a44222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******COUNT Vectorizer on AdaBoost Classifier*********\n",
      "Accuracy Score 0.3551\n",
      "F1 Score 0.4623\n",
      "Precision Score 0.8190\n",
      "Recall Score 0.3551\n",
      "\n",
      "\n",
      "******TFIDF Vectorizer on AdaBoost Classifier*********\n",
      "Accuracy Score 0.3523\n",
      "F1 Score 0.4589\n",
      "Precision Score 0.8141\n",
      "Recall Score 0.3523\n"
     ]
    }
   ],
   "source": [
    "# Adaboost classifier\n",
    "\n",
    "\n",
    "\n",
    "ada_tfidf = AdaBoostClassifier()\n",
    "ada_count = AdaBoostClassifier()\n",
    "\n",
    "ada_count.fit(X_train_count , Ytrain)\n",
    "ada_pred1 = ada_count.predict(X_test_count)\n",
    "print(\"******COUNT Vectorizer on AdaBoost Classifier*********\")\n",
    "get_basic_scores(ada_pred1 , Ytest)\n",
    "\n",
    "print(\"\\n\\n******TFIDF Vectorizer on AdaBoost Classifier*********\")\n",
    "ada_tfidf.fit(X_train_tdfif , Ytrain)\n",
    "ada_pred2 = ada_tfidf.predict(X_test_tdfif)\n",
    "get_basic_scores(ada_pred2 , Ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ac186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
